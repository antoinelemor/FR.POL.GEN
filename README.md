# FR.POL.GEN
## Un r√©pertoire (pour l'analyse textuelle) de l'ensemble des discours de politique g√©n√©rale de la Ve R√©publique
## English below 

## R√©sum√©

Ce r√©pertoire est d√©di√© √† l'analyse de donn√©es textuelles de l'ensemble des discours de politique g√©n√©rale de la Ve R√©publique, en utilisant des techniques de traitement du langage naturel et le LLM Mixtral 7x8b. Les donn√©es textuelles ont √©t√© extraites du web puis nettoy√©es √† partir du site: [vie publique](https://www.vie-publique.fr/discours-dans-lactualite/269993-les-declarations-de-politique-generale).

Les scripts d'annotation de ce r√©pertoire peuvent √™tre utilis√©s librement sur la base de donn√©e textuelle des discours, et les instructions modifi√©es afin de produire de nouvelles analyses. Nous remercierons les nouvelles √©tudes de citer en cons√©quence ce r√©pertoire. 

Nous avons produit une annotation manuelle sur un √©chantillon repr√©sentatif pour v√©rifier la performance de Mixtral 7x8b sur les t√¢ches d'annotation confi√©es, notamment la d√©tection du ton, de th√©matiques, et de sous-th√©matiques li√©es √† l'extr√™me droite. Les m√©triques g√©n√©rales expos√©es ci-dessous indique une tr√®s bonne performance g√©n√©rale, mod√©r√©e par une performance moyenne de rappel. Pour voir l'ensemble des m√©triques par sous-cat√©gorie, voir fin du Readme.  

|                              | N   | Pr√©cision | Rappel | F1   |
|------------------------------|-----|-----------|--------|------|
| D√©tection des th√©matiques    | 467 | 1         | 0.93   | 0.96 |
| D√©tection de droite extr√™me des th√©matiques | 127 | 1         | 0.73   | 0.84 |
| D√©tection du ton (positif, n√©gatif, neutre) | 400 | 0.94      | 0.94   | 0.93 |
| Ensemble                     | 994 | 1         | 0.89   | 0.94 |
| Annotation sur un √©chantillon repr√©sentatif de 400 phrases (IC 95%) |     |           |               |

Ce readme est organis√© et d√©crit par dossier, et explique bri√®vement les fonctionnalit√©s de chaque script par dossier ainsi que le contenu de chaque dossier. 

## üìÅ Scrap
### Dossier contenant les scripts d'extraction des textes de discours de politique g√©n√©rale

### Extract.py : Extraction des textes de discours de politique g√©n√©rale 
- **Fonctionnalit√© :** Extrait les discours de politique g√©n√©rale du site du site web [vie publique](https://www.vie-publique.fr/discours-dans-lactualite/269993-les-declarations-de-politique-generale) en utilisant le webdriver pour Firefox.
- **Biblioth√®ques utilis√©es :** `selenium`, `time` et le webdriver pour Firefox.

## üìÅ Texts
### Dossier contenant tous les textes de discous de politique g√©n√©ral extrait √† l'aide du script contenu dans 'Scrap'

## üìÅ Annotation
### Dossier contenant les scripts de pr√©paration et d'annotation de la base de donn√©es
## üìÅ Annotate

### 1_Database_aggregation.py : Cr√©ation de la base de donn√©es
- **Fonctionnalit√© :** Ce script est con√ßu pour agr√©ger les discours individuels √† partir d'un dossier et les compiler dans une base de donn√©es CSV unique contenue dans Database.
- **Biblioth√®ques utilis√©es :** `os`, et `csv`.
- **Processus :** 
  - Obtention du chemin absolu du dossier contenant les textes.
  - Lecture de chaque fichier texte, extraction du titre, de la date, de l'intervenant et du texte int√©gral.
  - Stockage des informations extraites dans une liste avec un identifiant unique pour chaque document.
  - √âcriture des donn√©es dans un fichier CSV avec une en-t√™te appropri√©e.
  - Gestion des chemins de fichiers relatifs et cr√©ation du dossier de sortie si n√©cessaire.

### 2_Preprocessed.py : Pr√©paration de la base de donn√©es pour annotation
- **Fonctionnalit√© :** Ce script pr√©-traite les textes de discours en tokenisant les phrases et en cr√©ant un contexte de trois phrases au total.
- **Biblioth√®ques utilis√©es :** `os`, `pandas`, `spacy`, et `sklearn.utils`.
- **Processus :**
  - Chargement de la base de donn√©es CSV des textes de discours.
  - Utilisation de spaCy pour tok√©niser les textes en phrases et construire leur contexte.
  - Cr√©ation d'un nouveau DataFrame contenant les identifiants de documents, les dates, les intervenants, et les contextes de phrases pour un ensemble s√©lectionn√© de discours.
  - M√©lange al√©atoire des discours avant l'application des fonctions pour garantir la vari√©t√© des donn√©es.
  - Enregistrement du nouveau DataFrame pr√©-trait√© dans un fichier CSV pour l'annotation.

### 3_Instructions.py : Insertion des instructions d'annotation
- **Fonctionnalit√© :** Ce script ajoute des instructions d'annotation sp√©cifiques visant √† d√©terminer la mesure dans laquelle ceux-ci peuvent √™tre d'extr√™me droite. **Ce script peut √™tre modifi√© pour ajouter d'autres inscrutions.**
- **Biblioth√®ques utilis√©es :** `os` et `pandas`.
- **Processus :**
  - Chargement d'un DataFrame √† partir d'un fichier CSV qui contient les textes de discours d√©j√† trait√©s.
  - D√©finition d'un dictionnaire o√π chaque cl√© correspond √† une t√¢che d'annotation sp√©cifique et chaque valeur est l'instruction textuelle associ√©e √† cette t√¢che.
  - It√©ration √† travers toutes les t√¢ches pour ajouter une nouvelle colonne dans le DataFrame pour chaque instruction d'annotation.
  - Sauvegarde du DataFrame enrichi d'instructions dans un nouveau fichier CSV pour guider le processus d'annotation des discours.

### 4_Annotate.py : Annotation automatis√©e de la base de donn√©es utilisant Mixtral 7x8b et Ollama
- **Fonctionnalit√© :** Automatisation de l'annotation des textes de discours politique g√©n√©rale en fonction de diff√©rentes cat√©gories et sous-cat√©gories, en utilisant le mod√®le Mixtral 7x8b et la biblioth√®que Ollama. **Le script devra √™tre modifi√© en fonction des nouvelles cat√©gories utilis√©es si le script d'instruction est modifi√©. 
- **Biblioth√®ques utilis√©es :** `pandas`, `ollama`, `unidecode` et `re`.
- **Processus :**
  - Configuration du mod√®le Mixtral 7x8b avec des param√®tres sp√©cifiques pour la g√©n√©ration de texte.
  - Chargement du fichier CSV qui contient les textes de discours avec les instructions d'annotation.
  - D√©finition des cat√©gories principales d'annotation et des sous-cat√©gories sp√©cifiques √† ces derni√®res.
  - Pour chaque ligne du DataFrame, g√©n√©ration automatique des r√©ponses aux questions d'annotation en utilisant le mod√®le configur√©.
  - Gestion des r√©ponses selon le type d'annotation demand√©, avec des expressions r√©guli√®res (oui/non) pour identifier les √©motions et th√®mes.
  - Compilation des r√©sultats dans un nouveau DataFrame, qui est ensuite sauvegard√© dans un fichier CSV.

### 5_Sentences_to_annotate.py : Calculer le nombre de phrases √† annoter pour obtenir un √©chantillon repr√©sentatif (IC 95%)
- **Fonctionnalit√© :** Ce script calcule la taille d'un √©chantillon repr√©sentatif de phrases n√©cessaires pour l'annotation.
- **Biblioth√®ques utilis√©es :** `os`, `pandas`, `spacy`, et `math`.
- **Processus :**
  - Chargement du corpus de textes de discours de politique g√©n√©rale √† partir d'un fichier CSV.
  - Utilisation de spaCy pour tokeniser le texte en phrases.
  - Calcul du nombre total de phrases dans le corpus.
  - D√©finition des param√®tres statistiques pour le niveau de confiance (95%) et la marge d'erreur (5%).
  - Application de la formule de taille d'√©chantillon ajust√©e pour une population finie afin de d√©terminer le nombre de phrases √† annoter pour que l'√©chantillon soit statistiquement repr√©sentatif.
  - Affichage du nombre total de phrases dans le corpus et du nombre de phrases recommand√© pour l'annotation.

### 6_Manual_annotation_processing.py : Cr√©ation d'un fichier JSONL pour annotation manuelle avec Doccano et v√©rification de l'efficacit√© du mod√®le
- **Fonctionnalit√© :** Ce script g√©n√®re un fichier JSONL √† partir d'un ensemble de donn√©es annot√© automatiquement, en vue d'une r√©vision manuelle. Il permet de v√©rifier l'efficacit√© de l'annotation automatique en s√©lectionnant un sous-ensemble de phrases √† partir de la base de donn√©es annot√©e.
- **Biblioth√®ques utilis√©es :** `pandas`, `os`, et `sklearn.utils`.
- **Processus :**
  - Chargement de deux fichiers CSV : l'un contenant des donn√©es annot√©es automatiquement et l'autre contenant des instructions d'annotation.
  - Nettoyage et pr√©paration des donn√©es en s'assurant de la coh√©rence des types de donn√©es pour la fusion.
  - S√©lection al√©atoire d'un nombre sp√©cifi√© de phrases pour l'√©chantillon √† r√©viser.
  - Fusion des donn√©es annot√©es et des instructions d'annotation bas√©es sur des cl√©s communes (doc_ID et sentence_id).
  - Cr√©ation de labels pour chaque th√©matique et variable sp√©cifique, en plus des cat√©gories d'√©motion et de th√®me, pour chaque extrait de discours.
  - Compilation des m√©tadonn√©es et des textes annot√©s dans un format JSONL pr√™t pour l'annotation manuelle ou la r√©vision.
  - Exportation du fichier JSONL, qui peut √™tre utilis√© dans des plateformes d'annotation ou pour des contr√¥les de qualit√© manuels.

### 7_Model_efficiency_FRS.py : Calcul des m√©triques d'annotation (F1, pr√©cision, rappel) pour les cat√©gories g√©n√©rales
- **Fonctionnalit√© :** Ce script est con√ßu pour √©valuer la performance de l'annotation automatique en comparant avec les annotations manuelles r√©alis√©es et en calculant les m√©triques d'efficacit√© telles que le score F1, la pr√©cision, et le rappel pour les cat√©gories g√©n√©rales et sp√©cifiques.
- **Biblioth√®ques utilis√©es :** `json`, `pandas`, `sklearn.metrics`, et `numpy`.
- **Processus :**
  - Extraction des annotations manuelles √† partir d'un fichier JSONL, o√π chaque ligne contient les annotations pour une phrase sp√©cifique.
  - Chargement des pr√©dictions g√©n√©r√©es par le mod√®le √† partir d'un fichier CSV.
  - Transformation des donn√©es pour les pr√©parer √† l'√©valuation, y compris la conversion des identifiants uniques et des labels d'annotation en formats binaires appropri√©s pour l'analyse.
  - Utilisation de la fonction `precision_recall_fscore_support` de scikit-learn pour calculer les m√©triques de performance sur l'ensemble des donn√©es, en tenant compte des cat√©gories d'annotation principales et extr√™mes.
  - Affichage des m√©triques calcul√©es pour une √©valuation globale, ainsi que s√©par√©e pour la d√©tection de cat√©gories g√©n√©rales et la d√©tection des cat√©gories extr√™mes.

### 7bis_Model_efficiency.py : Calcul des m√©triques d'annotation (F1, pr√©cision, rappel) pour l'ensemble des cat√©gories et sous-cat√©gories
- **Fonctionnalit√© :** Le script calcule des m√©triques d'annotation d√©taill√©es pour chaque cat√©gorie et sous-cat√©gorie, offrant une √©valuation compl√®te de la pr√©cision, du rappel, et du score F1 de l'annotation automatique par rapport √† l'annotation manuelle.
- **Biblioth√®ques utilis√©es :** `json`, `pandas`, `sklearn.metrics`, et `numpy`.
- **Processus :**
  - Extraction des annotations manuelles pr√©c√©demment r√©alis√©es √† partir d'un fichier JSONL, en associant chaque annotation √† son identifiant unique de document et de phrase.
  - Chargement et pr√©paration des pr√©dictions de l'annotation automatique √† partir d'un fichier CSV, convertissant les donn√©es pour la comparaison.
  - Calcul des m√©triques de performance pour chaque label individuel, y compris la pr√©cision, le rappel et le score F1, en utilisant des valeurs binaires pour les cat√©gories oui/non et un calcul pond√©r√© pour les cat√©gories √©motionnelles.
  - Compilation des m√©triques dans un DataFrame pour une repr√©sentation tabulaire et exportation en format CSV pour l'analyse.
  - Gestion des cas o√π il n'y a pas d'observations pour une cat√©gorie donn√©e en rempla√ßant les m√©triques par 'NA' pour refl√©ter l'absence de donn√©es.
  
### annotations_to_review.jsonl : Fichier JSONL contenant les annotations manuelles r√©alis√©es avec Doccano

## üìÅ Database
### Ce dossier sert de d√©p√¥t central pour tous les fichiers relatifs aux donn√©es des discours et aux fichiers g√©n√©r√©s par les scripts d'annotation.

#### `Speech_texts.csv`
- **Description :** Fichier CSV original contenant l'int√©gralit√© des textes de discours politique extraits pour l'analyse.

#### `Processed_speech_texts.csv`
- **Description :** Fichier CSV r√©sultant du script de pr√©traitement des discours, il contient les textes segment√©s en phrases avec leur contexte de trois phrases.

### `instructions_speech_texts.csv` ‚Äî ABSENT ‚Äî Fichier volumineux (>100Mo)
- **Description :** Ce fichier CSV contient les textes des discours politiques accompagn√©s d'instructions d'annotation d√©taill√©es pour chaque phrase. Ces instructions sont destin√©es √† guider les annotateurs dans le processus d'annotation manuelle.

#### `annotated_speech_texts.csv`
- **Description :** Ce fichier CSV inclut les textes des discours qui ont √©t√© annot√©s automatiquement en utilisant le mod√®le Mixtral 7x8b et Ollama. Il fournit un ensemble de donn√©es initiales avant la r√©vision manuelle.

#### `annotations_to_review.jsonl`
- **Description :** Ce fichier JSONL contient des extraits de discours s√©lectionn√©s pour l'examen et l'annotation manuelle. Utilis√© pour la v√©rification de l'efficacit√© du mod√®le d'annotation automatique.

#### `verification_annotation.jsonl`
- **Description :** Ce fichier JSONL est utilis√© pour stocker les annotations manuelles. Il sert de r√©f√©rence pour comparer et calculer l'efficacit√© des annotations automatiques par rapport √† celles manuelles.

### `PM`
- **Description :** Ce fichier contient des donn√©es √©lectorales et parlementaires pour des analyses de r√©gressions post√©rieures. 

## üìÅ Results
### Ce dossier contient des scripts produisant des r√©sultats d'analyse √† partir de l'annotation r√©alis√©e. Ces analyses fournissent une compr√©hension approfondie des tendances th√©matiques et √©motionnelles dans les discours de politique g√©n√©rake, notamment leur 'extr√™me droitisation'

### Database.R : Analyse statistique des textes de discours politique g√©n√©rale
- **Fonctionnalit√© :** Ce script R effectue des analyses statistiques avanc√©es, y compris le traitement des donn√©es, le calcul de proportions th√©matiques, des scores d'extr√™me droite, ainsi que des indices de n√©gativit√© et de positivit√© du discours. Il produit √©galement des visualisations et des r√©gressions statistiques pour interpr√©ter les tendances et les relations dans les donn√©es.
- **Biblioth√®ques utilis√©es :** `dplyr`, `ggplot2`, `lubridate`, `tidyverse`, `broom`, `forcats`, `RColorBrewer`, `readxl` 
- **Processus :**
  - **Chargement des donn√©es** : Les discours annot√©s sont charg√©s √† partir d'un fichier CSV.
  - **Pr√©paration des donn√©es** : Les donn√©es sont regroup√©es par document, date et intervenant, et des calculs sont effectu√©s pour d√©terminer le nombre total de phrases par discours.
  - **Analyse th√©matique** : Les donn√©es sont transform√©es pour calculer la proportion de chaque th√©matique d√©tect√©e par rapport au total des phrases, et ce, pour chaque date et intervenant.
  - **Calcul des scores d'extr√™me droite** : Les scores sont calcul√©s en fonction de la pr√©sence de th√©matiques sp√©cifiques et de leur intensit√©.
  - **R√©gressions et visualisations** : Des mod√®les de r√©gression sont construits pour analyser les impacts des diff√©rentes variables sur les scores politiques. Des graphiques d'interaction et des tableaux de corr√©lation sont g√©n√©r√©s pour visualiser ces relations.

### Results.R : Visualisation et analyse des r√©sultats des annotations
- **Fonctionnalit√© :** Ce script R g√©n√®re des visualisations et des analyses d√©taill√©es des donn√©es annot√©es, y compris des distributions th√©matiques, des proportions et des √©volutions temporelles des th√©matiques dans les discours politiques.
- **Biblioth√®ques utilis√©es :** `dplyr`, `ggplot2`, `lubridate`, `tidyverse`, `broom`, `forcats`, `RColorBrewer`
- **Processus :**
  - **Chargement et pr√©paration des donn√©es** : Importation des donn√©es annot√©es et ajustements pr√©liminaires pour assurer le bon format des dates et la consistance des variables.
  - **Visualisation des distributions th√©matiques** : Cr√©ation de graphiques √† barres pour montrer la fr√©quence des diff√©rentes th√©matiques d√©tect√©es dans les discours.
  - **Analyse des proportions des th√©matiques** : Calcul des proportions de chaque th√©matique par rapport au nombre total de phrases par discours, suivi par la visualisation de ces proportions pour identifier les tendances.
  - **√âvolution des th√©matiques dans le temps** : Visualisation de l'√©volution des proportions des th√©matiques au fil du temps avec des graphiques lin√©aires et ponctuels, mettant en √©vidence les changements dans l'usage des th√©matiques par les intervenants.
  - **Exportation des graphiques** : Les visualisations cr√©√©es sont sauvegard√©es dans des fichiers PDF pour une utilisation dans des rapports ou des pr√©sentations ult√©rieures.


# FR.POL.GEN
## A repository (for textual analysis) of all 'general policy speeches' of the Fifth French Republic

## Summary

This repository is dedicated to the textual data analysis of all general policy speeches of the Fifth Republic, using natural language processing techniques and the LLM Mixtral 7x8b. The textual data were extracted from the web and then cleaned from the site: [public life](https://www.vie-publique.fr/discours-dans-lactualite/269993-les-declarations-de-politique-generale).

The annotation scripts in this repository can be freely used on the textual database of the speeches, and the instructions modified to produce new analyses. We ask that any new studies using this repository appropriately cite it.

We have conducted manual annotation on a representative sample to verify the performance of Mixtral 7x8b on assigned annotation tasks, including tone detection, thematic detection, and sub-thematic detection related to the far right. The general metrics shown below indicate very good overall performance, moderated by average recall performance. To see all the metrics by subcategory, see end of the Readme.

|                              | N   | Precision | Recall | F1   |
|------------------------------|-----|-----------|--------|------|
| Thematic Detection           | 467 | 1         | 0.93   | 0.96 |
| Far-Right Thematic Detection | 127 | 1         | 0.73   | 0.84 |
| Tone Detection (positive, negative, neutral) | 400 | 0.94      | 0.94   | 0.93 |
| Overall                      | 994 | 1         | 0.89   | 0.94 |
| Annotation on a representative sample of 400 phrases (CI 95%) |     |           |               |

This README is organized and described by folder, and briefly explains the features of each script by folder as well as the content of each folder.

## üìÅ Scrap
### Folder containing scripts for extracting texts from general policy speeches

### Extract.py: Extraction of general policy speech texts
- **Functionality:** Extracts general policy speeches from the [public life](https://www.vie-publique.fr/discours-dans-lactualite/269993-les-declarations-de-politique-generale) website using the webdriver for Firefox.
- **Libraries used:** `selenium`, `time`, and the webdriver for Firefox.

## üìÅ Texts
### Folder containing all general policy speech texts extracted using the script in 'Scrap'

## üìÅ Annotation
### Folder containing scripts for preparing and annotating the database
## üìÅ Annotate

### 1_Database_aggregation.py: Database creation
- **Functionality:** This script is designed to aggregate individual speeches from a folder and compile them into a single CSV database contained in Database.
- **Libraries used:** `os`, and `csv`.
- **Process:**
  - Obtaining the absolute path of the folder containing the texts.
  - Reading each text file, extracting the title, date, speaker, and full text.
  - Storing the extracted information in a list with a unique identifier for each document.
  - Writing the data into a CSV file with an appropriate header.
  - Managing relative file paths and creating the output folder if necessary.

### 2_Preprocessed.py: Preparing the database for annotation
- **Functionality:** This script preprocesses speech texts by tokenizing sentences and creating a context of three sentences in total.
- **Libraries used:** `os`, `pandas`, `spacy`, and `sklearn.utils`.
- **Process:**
  - Loading the CSV database of speech texts.
  - Using spaCy to tokenize texts into sentences and construct their context.
  - Creating a new DataFrame containing document IDs, dates, speakers, and sentence contexts for a selected set of speeches.
  - Randomly shuffling speeches before applying functions to ensure data variety.
  - Saving the newly preprocessed DataFrame into a CSV file for annotation.

### 3_Instructions.py: Inserting annotation instructions
- **Functionality:** This script adds specific annotation instructions aimed at determining the extent to which they may be far-right. **This script can be modified to add other instructions.**
- **Libraries used:** `os` and `pandas`.
- **Process:**
  - Loading a DataFrame from a CSV file that contains preprocessed speech texts.
  - Defining a dictionary where each key corresponds to a specific annotation task and each value is the textual instruction associated with that task.
  - Iterating through all tasks to add a new column in the DataFrame for each annotation instruction.
  - Saving the enriched DataFrame of instructions into a new CSV file to guide the speech annotation process.

### 4_Annotate.py: Automated annotation of the database using Mixtral 7x8b and Ollama
- **Functionality:** Automates the annotation of general policy speech texts according to different categories and subcategories, using the Mixtral 7x8b model and the Ollama library. **The script will need to be modified according to new categories used if the instruction script is modified.**
- **Libraries used:** `pandas`, `ollama`, `unidecode`, and `re`.
- **Process:**
  - Configuring the Mixtral 7x8b model with specific parameters for text generation.
  - Loading the CSV file that contains speech texts with annotation instructions.
  - Defining main annotation categories and specific subcategories related to them.
  - For each row in the DataFrame, automatically generating responses to annotation questions using the configured model.
  - Handling responses according to the type of annotation requested, with regular expressions (yes/no) to identify emotions and themes.
  - Compiling the results into a new DataFrame, which is then saved into a CSV file.

### 5_Sentences_to_annotate.py: Calculating the number of sentences to annotate to obtain a representative sample (CI 95%)
- **Functionality:** This script calculates the size of a representative sample of sentences needed for annotation.
- **Libraries used:** `os`, `pandas`, `spacy`, and `math`.
- **Process:**
  - Loading the corpus of general policy speech texts from a CSV file.
  - Using spaCy to tokenize the text into sentences.
  - Calculating the total number of sentences in the corpus.
  - Setting statistical parameters for confidence level (95%) and margin of error (5%).
  - Applying the formula for adjusted sample size for a finite population to determine the number of sentences to annotate for the sample to be statistically representative.
  - Displaying the total number of sentences in the corpus and the recommended number of sentences for annotation.

### 6_Manual_annotation_processing.py: Creating a JSONL file for manual annotation with Doccano and checking model efficiency
- **Functionality:** This script generates a JSONL file from a set of automatically annotated data, intended for manual review. It allows checking the efficiency of automatic annotation by selecting a subset of sentences from the annotated database.
- **Libraries used:** `pandas`, `os`, and `sklearn.utils`.
- **Process:**
  - Loading two CSV files: one containing automatically annotated data and another containing annotation instructions.
  - Cleaning and preparing data by ensuring data type consistency for merging.
  - Randomly selecting a specified number of sentences for the sample to review.
  - Merging annotated data and annotation instructions based on common keys (doc_ID and sentence_id).
  - Creating labels for each theme and specific variable, in addition to emotion and theme categories, for each speech excerpt.
  - Compiling metadata and annotated texts into a JSONL format ready for manual annotation or quality checks.
  - Exporting the JSONL file, which can be used in annotation platforms or for manual quality controls.

### 7_Model_efficiency_FRS.py: Calculating annotation metrics (F1, precision, recall) for general categories
- **Functionality:** This script is designed to assess the performance of automatic annotation by comparing it with manually performed annotations and calculating efficiency metrics such as the F1 score, precision, and recall for general and specific categories.
- **Libraries used:** `json`, `pandas`, `sklearn.metrics`, and `numpy`.
- **Process:**
  - Extracting manual annotations from a JSONL file, where each line contains annotations for a specific sentence.
  - Loading model-generated predictions from a CSV file.
  - Transforming data to prepare for evaluation, including converting unique identifiers and annotation labels into appropriate binary formats for analysis.
  - Using the `precision_recall_fscore_support` function from scikit-learn to calculate performance metrics across the dataset, considering main and extreme annotation categories.
  - Displaying calculated metrics for a global evaluation, as well as separate for detecting general categories and detecting extreme categories.

### 7bis_Model_efficiency.py: Calculating annotation metrics (F1, precision, recall) for all categories and subcategories
- **Functionality:** The script calculates detailed annotation metrics for each category and subcategory, providing a comprehensive evaluation of precision, recall, and F1 score of automatic annotation compared to manual annotation.
- **Libraries used:** `json`, `pandas`, `sklearn.metrics`, and `numpy`.
- **Process:**
  - Extracting previously performed manual annotations from a JSONL file, linking each annotation to its unique document and sentence identifier.
  - Loading and preparing automatic annotation predictions from a CSV file, converting the data for comparison.
  - Calculating performance metrics for each individual label, including precision, recall, and F1 score, using binary values for yes/no categories and a weighted calculation for emotional categories.
  - Compiling metrics into a DataFrame for tabular representation and exporting in CSV format for analysis.
  - Handling cases where there are no observations for a given category by replacing metrics with 'NA' to reflect the absence of data.
  
### annotations_to_review.jsonl: JSONL file containing manually performed annotations with Doccano

## üìÅ Database
### This folder serves as a central repository for all files related to speech data and files generated by annotation scripts.

#### `Speech_texts.csv`
- **Description:** The original CSV file containing the full texts of political speeches extracted for analysis.

#### `Processed_speech_texts.csv`
- **Description:** Resulting CSV file from the preprocessing script of the speeches, it contains the texts segmented into sentences with their three-sentence context.

### `instructions_speech_texts.csv` ‚Äî ABSENT ‚Äî Large file (>100MB)
- **Description:** This CSV file contains the political speech texts accompanied by detailed annotation instructions for each sentence. These instructions are intended to guide annotators in the manual annotation process.

#### `annotated_speech_texts.csv`
- **Description:** This CSV file includes the texts of speeches that have been automatically annotated using the Mixtral 7x8b and Ollama model. It provides an initial dataset before manual revision.

#### `annotations_to_review.jsonl`
- **Description:** This JSONL file contains selected speech excerpts for review and manual annotation. Used for checking the efficiency of the automatic annotation model.

#### `verification_annotation.jsonl`
- **Description:** This JSONL file is used to store manual annotations. It serves as a reference for comparing and calculating the efficiency of automatic annotations against manual ones.

### `PM`
- **Description:** This file contains electoral and parliamentary data for subsequent regression analyses. 

## üìÅ Results
### This folder contains scripts producing analysis results from the performed annotations. These analyses provide an in-depth understanding of thematic and emotional trends in general policy speeches, including their 'far-rightization'

### Database.R: Statistical analysis of general policy speech texts
- **Functionality:** This R script performs advanced statistical analyses, including data processing, calculation of thematic proportions, far-right scores, as well as indices of speech negativity and positivity. It also produces visualizations and statistical regressions to interpret trends and relationships in the data.
- **Libraries used:** `dplyr`, `ggplot2`, `lubridate`, `tidyverse`, `broom`, `forcats`, `RColorBrewer`, `readxl`
- **Process:**
  - **Data Loading**: Annotated speeches are loaded from a CSV file.
  - **Data Preparation**: Data are grouped by document, date, and speaker, and calculations are performed to determine the total number of sentences per speech.
  - **Thematic Analysis**: Data are transformed to calculate the proportion of each detected theme relative to the total sentences, for each date and speaker.
  - **Extreme Right Score Calculation**: Scores are calculated based on the presence of specific themes and their intensity.
  - **Regressions and Visualizations**: Regression models are built to analyze the impacts of different variables on political scores. Interaction graphs and correlation tables are generated to visualize these relationships.

### Results.R: Visualization and analysis of annotation results
- **Functionality:** This R script generates detailed visualizations and analyses of the annotated data, including thematic distributions, proportions, and temporal evolutions of themes in political speeches.
- **Libraries used:** `dplyr`, `ggplot2`, `lubridate`, `tidyverse`, `broom`, `forcats`, `RColorBrewer`
- **Process:**
  - **Data Loading and Preparation**: Importing annotated data and making preliminary adjustments to ensure the correct format of dates and consistency of variables.
  - **Visualization of Thematic Distributions**: Creating bar charts to show the frequency of different detected themes in the speeches.
  - **Analysis of Thematic Proportions**: Calculating the proportions of each theme relative to the total number of sentences per speech, followed by visualizing these proportions to identify trends.
  - **Evolution of Themes Over Time**: Visualizing the evolution of thematic proportions over time with line and dot graphs, highlighting changes in theme usage by speakers.
  - **Exporting Graphs**: Created visualizations are saved in PDF files for use in later reports or presentations.


## D√©tails des performances d'annotation / Annotation Performance Details
### Le tableau ci-dessous d√©taille les performances d'annotation. Il doit √™tre not√© que les NA ne doivent pas √™tre intepr√©t√©s comme l'absence de v√©rification provenant de l'annotation manuelle, mais plut√¥t par l'absence totale de ces cat√©gories dans les donn√©es textuelle. 
### The table below details the annotation performances. It should be noted that NAs should not be interpreted as a lack of verification from manual annotation, but rather by the total absence of these categories in the textual data.


| Label                | Precision | Recall | F1 Score | N            |
|----------------------|-----------|--------|----------|--------------|
| emotion              | 0.942     | 0.94   | 0.934    | 400          |
| autorit√©_3           | 0.714     | 0.682  | 0.698    | 22           |
| autorit√©_1           | 1.0       | 0.5    | 0.667    | 6            |
| tradition_3          | 1.0       | 1.0    | 1.0      | 2            |
| prodem_1             | 0.875     | 0.583  | 0.7      | 12           |
| immigration_2        | 1.0       | 1.0    | 1.0      | 2            |
| tradition_1          | 0.81      | 0.944  | 0.872    | 18           |
| prodem_2             | 1.0       | 0.833  | 0.909    | 6            |
| progr√®s_1            | NA        | NA     | NA       | 0            |
| d√©mocratie_2         | 1.0       | 1.0    | 1.0      | 2            |
| tradition_5          | 1.0       | 1.0    | 1.0      | 1            |
| autorit√©_4           | 0.923     | 0.706  | 0.8      | 17           |
| tradition_4          | NA        | NA     | NA       | 0            |
| progr√®s_3            | NA        | NA     | NA       | 0            |
| tradition_6          | NA        | NA     | NA       | 0            |
| d√©mocratie_4         | NA        | NA     | NA       | 0            |
| nation_5             | 1.0       | 0.882  | 0.938    | 17           |
| √©galit√©_4            | NA        | NA     | NA       | 0            |
| √©galit√©_3            | NA        | NA     | NA       | 0            |
| d√©mocratie_3         | NA        | NA     | NA       | 0            |
| immigration_1        | NA        | NA     | NA       | 0            |
| d√©mocratie_5         | NA        | NA     | NA       | 0            |
| nation_2             | 1.0       | 0.5    | 0.667    | 2            |
| autorit√©_5           | 1.0       | 1.0    | 1.0      | 1            |
| √©galit√©_1            | NA        | NA     | NA       | 0            |
| nation_3             | 0.0       | 0.0    | 0.0      | 3            |
| immigration_3        | 1.0       | 0.5    | 0.667    | 2            |
| nation_6             | 0.536     | 0.882  | 0.667    | 17           |
| tradition_2          | 1.0       | 0.5    | 0.667    | 2            |
| autorit√©_2           | 0.833     | 0.5    | 0.625    | 10           |
| progr√®s_2            | NA        | NA     | NA       | 0            |
| nation_4             | 0.0       | 0.0    | 0.0      | 2            |
| √©galit√©_2            | NA        | NA     | NA       | 0            |
| d√©mocratie_1         | NA        | NA     | NA       | 0            |
| prodem_3             | 1.0       | 0.333  | 0.5      | 3            |
| nation_1             | 0.0       | 0.0    | 0.0      | 1            |
| immigration_4        | NA        | NA     | NA       | 0            |
| detect_d√©mocratie    | 1.0       | 0.964  | 0.982    | 83           |
| detect_immigration   | 1.0       | 0.7    | 0.824    | 10           |
| detect_progr√®s       | 1.0       | 1.0    | 1.0      | 127          |
| detect_ue            | 1.0       | 0.944  | 0.971    | 18           |
| detect_ecologie      | 1.0       | 0.5    | 0.667    | 18           |
| detect_tech          | 1.0       | 1.0    | 1.0      | 18           |
| detect_soc           | 0.986     | 0.972  | 0.979    | 72           |
| detect_√©galit√©       | 0.96      | 0.923  | 0.941    | 26           |
| detect_travail       | 1.0       | 1.0    | 1.0      | 78           |
| detect_nation        | 0.94      | 0.94   | 0.94     | 116          |
| detect_autorit√©      | 0.921     | 0.843  | 0.881    | 83           |
| detect_prodem        | 0.975     | 0.907  | 0.94     | 86           |
| detect_tradition     | 0.952     | 0.909  | 0.93     | 22           |
